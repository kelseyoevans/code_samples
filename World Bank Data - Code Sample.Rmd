---
title: "363 Final Project Report"
author: "Kelsey Evans, Megan Ahern, Armin Thomas"
date: "May 4, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include = FALSE, warning = FALSE, message = FALSE}
library(heplots)
library(corrplot)
library(pls)
library(psych)
library(cluster)
library(fpc)
library(contrast)

WB5 <- read.csv("WB5.csv", header = TRUE)
rownames(WB5) <- WB5[, 1]
WB5 <- WB5[, -1]
WB5$logRefugee <- log(WB5$Refugee)
WB5$logCO2 <- log(WB5$CO2)
WB5$logFertility <- log(WB5$Fertility)
WB5$logEnergy <- log(WB5$Energy)
WB5$logOutput <- log(WB5$Output)
WB5$logPopBelow <- log(WB5$PopBelow)
WB5$logLegalRights <- log(WB5$LegalRights)
WB5 <- WB5[, c(1:4, 8, 13:19)]
WB5 <- WB5[complete.cases(WB5[, 1:12]), 1:12]
is.na(WB5) <- sapply(WB5, is.infinite)
WB5[is.na(WB5)] <- 0
WB5 <- droplevels(WB5, exclude = "")
WB5 <- WB5[c(1:55, 57:64), ]


WB1 <- WB5[ ,c(1, 2, 4, 7, 8, 9)]   #MANOVA
WB2 <- WB5[ , c(3:12)]     #all else
```

### Introduction 

#### Background and Motivation

The motivation for this project was to examine relationships between different 
indicator categories, like socio-economic, energy, and environmental indicators. 
We each chose several indicators that were personally interesting.  For example, 
Megan was interested in the environment, so she made sure to include factors like 
forest area and CO2 emissions, Kelsey was interested in factors relating to women's 
rights, like Gender in the Constitution and Fertility rates, and Armin was interested 
in factors relating to development, such as the legal rights index. We hoped to 
see these different indicators relate to each other. 

#### Design and Primary Questions

We've chosen to use PCA, Factor Analysis, Cluster Analysis, and 
MANOVA for this project. 

Some questions: 

* How do the indicators relate to one another? 
* How do categorical variables predict continuous variables?
* Can we find interesting insight by grouping countries together?
* Might there be latent factors that explain these relationships? 

#### Data

We scraped our data off of the World Bank site, using information from the year 
2016.  The cleaning process included putting the data into an excel spreadsheet 
which was converted to a CSV so it could be used in R. We took the log of about 
half of these indicators after examining normal quantile plots. We chose the 
following indicators:

#### Categorical:
*	**Region**: (NAm = North America, SLA = South/Latin America, AS = Arab States, EUR = Europe, AF = Africa,
AP = Asia/Pacific)
*	**IncomeGrp**: (1.L = Low, 2.LM = Lower Middle, 3.UM = Upper Middle, 4.H = High)

#### Continuous: 
*	**Gender**: Mention of Gender in the Constitution, units: 1=yes; 0=no 
(this is technically a binary variable, but we used it as continuous)
*	**logLegalRights**: Strength of Legal Rights, units: 0=weak to 12=strong 
(while this is a 0-12 scale, we are also confident in using it as a continuous variable)
*	**logCO2**: CO2 output, units: metric tons per capita
*	**LogEnergy**: Energy Consumption, units: kg of oil equivalent per capita
*	**CleanCook**: Access to Clean Cooking Fuel, units: % of population
*	**logFertility**: Fertility Rate, units: births per woman
*	**logPopBelow**: Percent of Population below 5 meters of elevation, units: % of population
*	**ForestArea**: Forest Area, units: % of land area
*	**logRefugee**: Refugee Population by country of asylum, units: # of persons
* **logOutput**: Renewable Energy Output, units: % of total electricity output


Here is an example of the data: 

```{r, echo = FALSE}
head(WB5)
```


### Principal Components Analysis

First, we will do principal components analysis to try to explain some of the 
variability in our data. In order to do this, our data would optimally be 
multivariate normal. We can examine this by creating a chi-square quantile plot: 

```{r, echo = FALSE}
# Chi-sq Plot: 
cqplot(WB2)
```

The chi-square quantile plot looks approximately normal. We have only two points 
outside of the 95% confidence bands, so we feel confident that we can perform PCA 
on the data. Additionally, the multivariate normality will be useful for the other methods. 



We also would like to look at a correlation matrix just to get an idea of which 
variables are strongly correlated: 

```{r, echo = FALSE}
corrplot.mixed(cor(WB2), lower.col = "forest green", upper = "ellipse", tl.col = 
                 "black", number.cex = 0.7, order = "hclust",tl.pos = 
                 "lt", tl.cex = 0.7)
```



Now that we've examined the data, we can continue with Principal Components 
Analysis. In order to figure out how many components we'd like to keep, we 
will use three methods: the eigenvalue method, a scree plot, and parallel 
analysis. 

The eigenvalues are as follows: 

```{r, echo = FALSE}
pc1 <- princomp(WB2, cor=TRUE)
round(pc1$sdev^2,2)
```

The first three components are all greater than 1, so this test indicates that 
we should keep three components. 



Next we will look at the scree plot: 

```{r, echo = FALSE}
screeplot(pc1,type="lines",col="red",lwd=2,pch=19,cex=0.8,main=
            "Scree Plot of WB Data")
```

This plot has an "elbow" at 4, which also indicates that we should keep three 
components. 


(We have also recognized that these three components only explain around 70% of 
the data, while 80% would be ideal, though it would require five components. 
However, all of the other tests indicated that three components was best, so we 
would only expand to 5 if 80% of variability was explicitly required.)


To check the validity of our tests, we made a score plot to see if there were 
any unusual trends in the data: 

```{r, echo = FALSE}
WB2$names <- rownames(WB2)
scoreplot(pc1, c(1,2), WB2[,11])
WB2 <- WB2[, -11]
```

There are no other observable trends, so we are 
confident in our tests. 



We looked at the loadings and the individual components to see if there was any 
story told by the data. We looked at components with an absolute value of greater 
than 0.4, and only the first component seems to tell a consistent story. The 
variable exceeding 0.4 are CleanCook, logCO2, and logEnergy, which are all energy 
use factors. The other components, while significant, don't tell a discernable 
story. 

```{r, echo = FALSE, warning = FALSE, message = FALSE}
print(summary(pc1),digits=2,loadings=pc1$loadings,cutoff=0)
```

By using PCA, we saw a component of environmental/energy related variables as 
explaining a lot of the variance in the world bank data. This is what we set out 
to see for this project - whether certain groups of variables could help explain 
trends in the data. However, for PCA there isn't always a coherent story - it's 
more about explaining the most variance. It is nice when there is also a story, 
but this isn't always the case. 


### Factor Analysis

We chose to do factor analysis next because it contains aspects of PCA, at least 
in choosing how many factors to look for. We referred to the correlation matrix 
from the previous section to look at which variables were most strongly correlated. 

We observed that the largest correlations were positive correlations between log 
Energy and log CO2, log CO2 and clean cooking fuel, and log Energy and clean 
cooking fuel. The best negative correlation was between fertility and clean 
cooking fuel. We saw poor correlations between gender and all other indicators. 
Most interestingly, Gender and log Legal Rights have no notable correlation. 

Observing our correlation matrices, we would say that factor analysis may be 
appropriate because we observed some correlations between indicators that may 
share a latent factor. For instance, a latent factor could simply be Energy or 
Development. 

First we computed the KMO measure to see if factor analysis was appropriate: 

```{r, echo = FALSE}
fact1 = KMO(WB2)
fact1$MSA
```

The KMO measure is 0.72, so factor analysis is a satisfactory option. 

Next, we referred to the previous section and chose to use 3 factors by using 
the PCA method of choosing factors. 

We chose to do the Principal Axis Factoring (PAF) method of factor analysis, 
both with and without the varimax rotation. For each, we computed the RMSR and 
the percent of residuals greater than 0.05 to determine which method was better. 

For PAF: 

```{r, include = FALSE}
(fact1 <- fa(WB2, nfactors = 3, fm = "pa"))
repro1 <- fact1$loadings%*%t(fact1$loadings)
resid1 <- cor(WB2)-repro1
round(resid1,2)
len1 <- length(resid1[upper.tri(resid1)])

```

RMSR: 

```{r, echo = FALSE}
(RMSR1 <- sqrt(sum(resid1[upper.tri(resid1)]^2)/len1))
```

Percent of residuals: 

```{r, echo = FALSE}
sum(rep(1,len1)[abs(resid1[upper.tri(resid1)])>0.05])/len1
```

For PAF with varimax: 

```{r, include = FALSE}
fact2 <- fa(WB2, nfactors = 3, fm = "pa", rotate = "varimax")
repro2 <- fact2$loadings%*%t(fact2$loadings)
resid2 <- cor(WB2)-repro2
round(resid2,2)
len2 <- length(resid2[upper.tri(resid2)])
```

RMSR: 

```{r, echo = FALSE}
(RMSR2 <- sqrt(sum(resid2[upper.tri(resid2)]^2)/len2))
```

Percent of residuals: 

```{r, echo = FALSE}
sum(rep(1,len2)[abs(resid2[upper.tri(resid2)])>0.05])/len2
```


Clearly, the results are better with the varimax rotation. We will use this to 
create a loading plot: 


```{r}
plot(fact2$loadings)
text(fact2$loadings, labels=names(WB2),cex=0.8)
```

Though the plot seems to contain three groups of variables, it's difficult to 
ascertain exactly what the factors would be. It seems that two of the groups of 
variables load more heavily on the first pricipal axis, and two as well on the 
second. Interestingly, similarly to PCA, it seems that the energy-related 
variables remain grouped together to form a factor. This could be because we 
used the PCA method to choose the number of factors, or because energy-related 
variables are generally very strong predictors in general. 


### Cluster Analysis

For cluster analysis, we first created a data set that was normally scaled. This 
is important for cluster analysis because variables should be on the same scale 
in order to see how close they are to each other. 

We tried several methods of clustering and found that the dendrogram we liked 
best was Euclidean Distance with Ward Method Linking: 

```{r, echo = FALSE}
WB2Sc <- scale(WB2)

dist1 <- dist(WB2Sc, method="euclidean")
clust1 <- hclust(dist1, method = "ward.D2")
plot(clust1,labels= rownames(WB2Sc), cex=0.6, xlab="",ylab="Distance",main=
       "Clustering of Countries, Euclidean & Ward") 
```

After trying various values, we settled on 10 clusters: 


```{r, echo = FALSE}
plot(clust1,labels= rownames(WB2Sc), cex=0.6, xlab="",ylab="Distance",main=
       "Clustering of Countries")
rect.hclust(clust1, k=10)
```


Next, we looked at Principal Components and Discriminant Analysis graphs of the 
clusters. 

```{r, echo = FALSE}
cuts <- cutree(clust1, k=10)
clusplot(WB2Sc, cuts, color=TRUE, shade=TRUE, labels=2, lines=0,
main="World Bank 10 Cluster Plot, Avg Method, First two PC", cex = 0.75)
plotcluster(WB2Sc, cuts, main="10 Cluster Solution in DA Space",
xlab="First Discriminant Function", ylab="Second Discriminant Function", 
cex = 0.75)
```

In both graphs, the ten clusters are pretty easily discernible. 

After this, we applied k-means to the data. First, we created the Cluster 
Solutions Against Log of SSE and Cluster Solutions against (Log of SSE - Random SSE) 
graphs to check on the number of clusters we were using. 

```{r, echo = FALSE}
km1 <- kmeans(WB2Sc,centers=10)

kdata <- WB2Sc
n.lev <- 15  #set max value for number of clusters k

# Calculate the within groups sum of squared error (SSE) for the number of 
#cluster solutions selected by the user
wss <- rnorm(10)
while (prod(wss==sort(wss,decreasing=T))==0) {
  wss <- (nrow(kdata)-1)*sum(apply(kdata,2,var))
  for (i in 2:n.lev) wss[i] <- sum(kmeans(kdata, centers=i)$withinss)}

# Calculate the within groups SSE for 250 randomized data sets (based on the 
#original input data)
k.rand <- function(x){
  km.rand <- matrix(sample(x),dim(x)[1],dim(x)[2])
  rand.wss <- as.matrix(dim(x)[1]-1)*sum(apply(km.rand,2,var))
  for (i in 2:n.lev) rand.wss[i] <- sum(kmeans(km.rand, centers=i)$withinss)
  rand.wss <- as.matrix(rand.wss)
  return(rand.wss)
}

rand.mat <- matrix(0,n.lev,250)

k.1 <- function(x) { 
  for (i in 1:250) {
    r.mat <- as.matrix(suppressWarnings(k.rand(kdata)))
    rand.mat[,i] <- r.mat}
  return(rand.mat)
}

# Same function as above for data with < 3 column variables
k.2.rand <- function(x){
  rand.mat <- matrix(0,n.lev,250)
  km.rand <- matrix(sample(x),dim(x)[1],dim(x)[2])
  rand.wss <- as.matrix(dim(x)[1]-1)*sum(apply(km.rand,2,var))
  for (i in 2:n.lev) rand.wss[i] <- sum(kmeans(km.rand, centers=i)$withinss)
  rand.wss <- as.matrix(rand.wss)
  return(rand.wss)
}

k.2 <- function(x){
  for (i in 1:250) {
    r.1 <- k.2.rand(kdata)
    rand.mat[,i] <- r.1}
  return(rand.mat)
}

# Determine if the data data table has > or < 3 variables and call appropriate 
#function above
if (dim(kdata)[2] == 2) { rand.mat <- k.2(kdata) } else { rand.mat <- k.1(kdata) }

# Plot within groups SSE against all tested cluster solutions for actual and 
#randomized data - 1st: Log scale, 2nd: Normal scale

xrange <- range(1:n.lev)
yrange <- range(log(rand.mat),log(wss))
plot(xrange,yrange, type='n', xlab='Cluster Solution', ylab=
       'Log of Within Group SSE', main='Cluster Solutions against Log of SSE')
for (i in 1:250) lines(log(rand.mat[,i]),type='l',col='red')
lines(log(wss), type="b", col='blue')
legend('topright',c('Actual Data', '250 Random Runs'), col=c('blue', 'red'), 
       lty=1)


# Calculate the mean and standard deviation of difference between SSE of actual 
#data and SSE of 250 randomized datasets
r.sse <- matrix(0,dim(rand.mat)[1],dim(rand.mat)[2])
wss.1 <- as.matrix(wss)
for (i in 1:dim(r.sse)[2]) {
  r.temp <- abs(rand.mat[,i]-wss.1[,1])
  r.sse[,i] <- r.temp}
r.sse.m <- apply(r.sse,1,mean)
r.sse.sd <- apply(r.sse,1,sd)
r.sse.plus <- r.sse.m + r.sse.sd
r.sse.min <- r.sse.m - r.sse.sd

# Plot differeince between actual SSE mean SSE from 250 randomized datasets - 
#1st: Log scale, 2nd: Normal scale 

xrange <- range(1:n.lev)
yrange <- range(log(r.sse.plus),log(r.sse.min))
plot(xrange,yrange, type='n',xlab='Cluster Solution', ylab=
       'Log of SSE - Random SSE', main=
       'Cluster Solutions against (Log of SSE - Random SSE)')
lines(log(r.sse.m), type="b", col='blue')
lines(log(r.sse.plus), type='l', col='red')
lines(log(r.sse.min), type='l', col='red')
legend('topright',c('SSE - random SSE', 'SD of SSE-random SSE'), 
       col=c('blue', 'red'), lty=1)
```

```{r, include = FALSE}
clust.level <- 10
fit <- kmeans(kdata, clust.level)
aggregate(kdata, by=list(fit$cluster), FUN=mean)
clust.out <- fit$cluster
kclust <- as.matrix(clust.out)
kclust.out <- cbind(kclust, WB2Sc)
```


Interestingly, these graphs seem to suggest using five clusters instead of ten. 
Howver, in looking at the original hclus_eval graph, an argument could be made 
for five or ten clusters. The same can be said for just looking at the graph and
estimating the number of clusters - we could either choose five bigger clusters 
of countries or ten smaller ones. 

Finally, we looked at the PCA graph with the new k-means data. Just like
before, the 10 clusters are visible. 

```{r, echo = FALSE}
clusplot(kdata, fit$cluster, shade=F, labels=2, lines=0, color=T, lty=4, 
         main='Principal Components plot showing K-means clusters', cex = 0.75)
```

It's difficult to compare the results of cluster analysis to the other methods, 
as we clustered on countries instead of on variables. A topic for future analysis 
could be looking at the ten clusters of countries to see what each has in common. 
For instance, the United States, Canada, Switzerland, and Japan are all in the 
same cluster, and are all wealthy and more developed countries. These countries 
are likely similar in terms of socioeconomic, environmental, and other indicators. 


###MANOVA

For MANOVA, we will look at the categorical variables of income and region, and 
the continuous variables of CleanCook, logCO2, logFertility, and logEnergy. 

To start off, we made a couple of interaction plots to see how the data looked 
by region and income: 

```{r, echo = FALSE}
interaction.plot(WB1$IncomeGrp, WB1$Region, WB1$logCO2, lwd=3,
                 col=c("red","blue","black", "green", "pink", "orange"),xlab="Income",main="Interaction Plot for CO2", cex = 0.75)

interaction.plot(WB1$IncomeGrp, WB1$Region, WB1$logFertility, lwd=3,
                 col=c("red","blue","black",
"green", "pink", "orange"),xlab="Income",main="Interaction Plot for Fertility", 
cex = 0.75)
```

Looking at the two graphs, we see that there's a possible interaction between 
income and region, though we will have to run a regression to make sure. But with
fertility, there's a significant difference by region. Fertility still decreases 
as income increases, but region seems to be more significant. As a note, North 
America does not appear in either interaction plot. This is because during data 
cleaning, the United States was the only North American country with complete 
data for this subset of data we chose for MANOVA. 

Next, we ran several regressions and found that the best one predicted the 
continuous variables using income, region, and the interaction between income 
and region. 

```{r, echo = FALSE}
mod1 <- manova(as.matrix(WB1[ , c(3:6)]) ~ WB5$IncomeGrp + WB1$Region + 
                 WB1$IncomeGrp*WB1$Region)
summary.aov(mod1)
```


As is evidenced in the significance charts, both income and region, as well as 
their interaction, is significant for all of the continous variables. There is 
one exception: The interaction term is not significant for fertility. On a 
cursory glance, this makes sense, as our initial interaction plot indicated 
that so much variability in fertility was explained by region that it might 
not even need the interaction. 

After this, we looked at a few univariate contrasts, for which we decided to use 
region. Befre that, we looked at some boxplots: 

```{r, echo = FALSE}
boxplot(logCO2 ~ Region, data = WB1, col = "lavender", ylab = "CO2", main = 
          "World Bank Data, CO2 by Region", cex = 0.75)
```

Just like earlier, North America contains only one data point and this is evident 
in the boxplot. To look at the contrasts, we set Asia Pacific as the constant.

```{r, echo = FALSE}
WB1aov <- lm(logCO2 ~ Region, data = WB1)
contrast1 <- contrast(WB1aov, list(Region = c("SLA", "AF", "AS", "NAm", "EUR")),
                      list(Region = "AP"),type='average')
print(contrast1,X=TRUE)
```

The contrast was not statistically significant. We think it's because the Asia 
Pacific mean is close to group mean, and also it has the largest spread 
(excluding outliers). 

Finally, we looked at a chi-square residual plot to check the accuracy of our 
MANOVA: 

```{r, echo = FALSE}
cqplot(mod1$residuals, label = "Residuals from World Bank ANOVA")
```

The residuals appear approximately multivariate normal, which means we feel 
confident in our analysis. 

MANOVA was the first time we introduced categorical variables. Here, it's easier
to see which variables were the explanatory and response variables, as opposed to 
the other methods which have more to do with creating groups of variables than 
creating an equation to predict a response variable. 

### Conclusion 

We looked back on the questions that we stated at the beginning of our project, 
and noted a few insights: 

* How do the indicators relate to one another? 
    + The biggest trend we noticed was the tendency of energy variables often 
    move together. 
* How do categorical variables predict continuous variables?
    + They were very significant predictors. In the example of fertility, region 
    and income were so significant in predicting fertility rates that the 
    interaction between them was not significant. 
* Can we find interesting insight by grouping countries together?
    + Our findings from Cluster Analysis were ultimately very different than 
    those of PCA and Factor Analysis because we based it on countries. We were 
    able to see some interesting groupings, namely a group of highly developed 
    countries (e.g. US, Canada, Switzerland, and Japan). The reason behind these 
    groupings might be a topic for future research. 
* Might there be latent factors that explain these relationships? 
    + Certainly. Many of our indicators might be the results of other hidden 
    indicators, such as a "development" indicator. 





_